{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from spluslib import SplusService, ImageType\n",
    "from xmatchlib import XTable, CrossMatch\n",
    "from utils import load_table, save_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_download_cluster_region(\n",
    "  cluster: List[str], \n",
    "  central_ra:List[float], \n",
    "  central_dec: List[float], \n",
    "  radius: List[float], \n",
    "  zml_min: List[float], \n",
    "  zml_max: List[float]\n",
    "):\n",
    "  query_template = \"\"\"\n",
    "  SELECT \n",
    "    dual_g.ID, dual_g.RA, dual_g.DEC, dual_g.Field, \n",
    "    dual_g.g_auto, dual_r.r_auto, dual_i.i_auto, dual_r.r_aper_6,\n",
    "    photoz.zml, photoz.odds, morpho.PROB_GAL, '{cluster}' AS cluster\n",
    "  FROM\n",
    "    idr4_dual_g AS dual_g\n",
    "    INNER JOIN\n",
    "    idr4_dual_i AS dual_i ON dual_i.ID = dual_g.ID\n",
    "    INNER JOIN\n",
    "    idr4_dual_r AS dual_r ON dual_r.ID = dual_g.ID\n",
    "    INNER JOIN\n",
    "    idr4_photoz AS photoz ON photoz.ID = dual_g.ID\n",
    "    INNER JOIN\n",
    "    idr4_star_galaxy_quasar AS morpho ON morpho.ID = dual_g.ID\n",
    "  WHERE\n",
    "    photoz.zml BETWEEN {zml_min} AND {zml_max} AND\n",
    "    1 = CONTAINS(\n",
    "      POINT('ICRS', dual_g.ra, dual_g.dec), \n",
    "      CIRCLE('ICRS', {ra}, {dec}, {radius})\n",
    "    )\n",
    "  \"\"\"\n",
    "  \n",
    "  query = [\n",
    "    query_template.format(\n",
    "      cluster=_cluster, \n",
    "      ra=_central_ra, \n",
    "      dec=_central_dec, \n",
    "      radius=_radius, \n",
    "      zml_min=_zml_min, \n",
    "      zml_max=_zml_max\n",
    "    ) for _cluster, _central_ra, _central_dec, _radius, _zml_min, _zml_max \n",
    "      in zip(cluster, central_ra, central_dec, radius, zml_min, zml_max)\n",
    "  ]\n",
    "\n",
    "  save_path = [\n",
    "    Path('outputs_v3') / f'cluster_{_cluster}.csv' for _cluster in cluster\n",
    "  ]\n",
    "\n",
    "  sp = SplusService(username='natanael', password='natan')\n",
    "  sp.batch_query(query, save_path=save_path, replace=True, scope='private', workers=7)\n",
    "  \n",
    "  \n",
    "def concat_tables(paths, save_path):\n",
    "  df = load_table(paths[0])\n",
    "  \n",
    "  for i in tqdm(range(1, len(paths))):\n",
    "    df2 = pd.read_csv(paths[i])\n",
    "    df = pd.concat((df, df2), ignore_index=True)\n",
    "  \n",
    "  df = df[df.columns.drop(list(df.filter(regex='Unnamed:*')))]\n",
    "  save_table(df, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Initial search table: 37\n",
      ">> Search table after z filter: 33\n",
      ">> Search table after available filter: 33\n",
      ">> Downloading photo catalog for all clusters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [22:12<00:00, 40.38s/ files] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Crossmatch with spec catalog\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [01:24<00:00,  2.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:09<00:00,  3.53it/s]\n"
     ]
    }
   ],
   "source": [
    "PHOTOZ_RANGE = 0.04\n",
    "Z_RANGE = 0.02\n",
    "\n",
    "cm = CrossMatch()\n",
    "# df_z_cluster = load_table('public/catalog_chinese_xray.csv')\n",
    "df_search = load_table('tables/catalog_chinese_xray_xmatch_splus_z0.1.csv')\n",
    "print(f'>> Initial search table: {len(df_search)}')\n",
    "df_search = df_search[df_search['z'].between(0.02, 0.1)]\n",
    "print(f'>> Search table after z filter: {len(df_search)}')\n",
    "df_search = df_search[~df_search['ra'].isnull() & ~df_search['dec'].isnull()]\n",
    "print(f'>> Search table after available filter: {len(df_search)}')\n",
    "df_search['name'] = df_search['name'].str.replace('_', '-')\n",
    "\n",
    "df_spec = pd.read_csv('tables/SpecZ_Catalogue_20230830.csv', low_memory=False)\n",
    "df_spec = df_spec[df_spec['z'].between(0.02 - Z_RANGE, 0.1 + Z_RANGE)]\n",
    "df_spec = df_spec.reset_index().copy(deep=True)\n",
    "\n",
    "df_radius = pd.read_csv('tables/z_rad15mpc-degb.dat', sep=' ')\n",
    "\n",
    "\n",
    "cluster_download_params = {\n",
    "  'cluster': [], 'central_ra': [], 'central_dec': [], \n",
    "  'radius': [], 'zml_min': [], 'zml_max': []\n",
    "}\n",
    "for _, row in df_search.iterrows():\n",
    "  search_radius = df_radius.iloc[(df_radius['z'] - row['z']).abs().argsort()[:1]]['radius'].values[0]\n",
    "  cluster_redshift = row['z']\n",
    "  cluster_download_params['cluster'].append(row['name'])\n",
    "  cluster_download_params['central_ra'].append(row['ra'])\n",
    "  cluster_download_params['central_dec'].append(row['dec'])\n",
    "  cluster_download_params['radius'].append(search_radius)\n",
    "  cluster_download_params['zml_min'].append(cluster_redshift - PHOTOZ_RANGE)\n",
    "  cluster_download_params['zml_max'].append(cluster_redshift + PHOTOZ_RANGE)\n",
    "\n",
    "print('>> Downloading photo catalog for all clusters')\n",
    "batch_download_cluster_region(\n",
    "  cluster=cluster_download_params['cluster'], \n",
    "  central_ra=cluster_download_params['central_ra'], \n",
    "  central_dec=cluster_download_params['central_dec'], \n",
    "  radius=cluster_download_params['radius'], \n",
    "  zml_min=cluster_download_params['zml_min'], \n",
    "  zml_max=cluster_download_params['zml_max'],\n",
    ")\n",
    "\n",
    "print('>> Crossmatch with spec catalog')\n",
    "for _, row in tqdm(df_search.iterrows(), total=len(df_search)):\n",
    "  cluster_redshift = row['z']\n",
    "  path = Path('outputs_v3') / f'cluster_{row[\"name\"]}.csv'\n",
    "  cluster_photo = load_table(path)\n",
    "  mask = cluster_photo['zml'].between(cluster_redshift - PHOTOZ_RANGE, cluster_redshift + PHOTOZ_RANGE)\n",
    "  cluster_photo = cluster_photo[mask].reset_index().copy(deep=True)\n",
    "  \n",
    "  xt_base = XTable(ra='RA', dec='DEC', df=cluster_photo)\n",
    "  xt_spec = XTable(ra='RA', dec='DEC', df=df_spec, columns=['z', 'e_z'])\n",
    "  \n",
    "  cm = CrossMatch()\n",
    "  match = cm.left_join(xt_base, xt_spec, radius=1)\n",
    "  match_df = match.table\n",
    "  match_df = match_df[\n",
    "    ~match_df['z'].isna() | # objects with spec\n",
    "    (\n",
    "      match_df['z'].isna() & \n",
    "      match_df['zml'].between(cluster_redshift - Z_RANGE, cluster_redshift + Z_RANGE)\n",
    "    ) # objects wo spec but within a lower photoz range\n",
    "  ]\n",
    "  match_df.to_csv(Path('outputs_v3') / (path.stem + '_photo+spec.csv'), index=False)\n",
    "  \n",
    "print('>> Concatenate tables')\n",
    "concat_tables(list(Path('outputs_v3').glob('*photo+spec.csv')), 'outputs_v3/clusters_v3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Preparing tables to send\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:06<00:00,  5.03it/s]\n"
     ]
    }
   ],
   "source": [
    "print('>> Preparing tables to send')\n",
    "for path in tqdm(list(Path('outputs_v3').glob('*photo+spec.csv'))):\n",
    "  tb = load_table(path)\n",
    "  cluster_name = tb['cluster'].values[0]\n",
    "  tb = tb[['RA', 'DEC', 'z', 'e_z']]\n",
    "  tb = tb[~tb['z'].isna()] # filter objects without spec\n",
    "  tb['e_z'] = tb['e_z'].fillna(0) # nan error -> 0.0\n",
    "  tb = tb.rename(columns={'z': 'zspec', 'e_z': 'zspec-err'})\n",
    "  tb.to_csv('outputs_v3/paulo/' + 'cluster_' + cluster_name + '_objects.csv', index=False)\n",
    "  df_search_copy = df_search[['ra', 'dec', 'z']]\n",
    "  df_search_copy = df_search_copy.rename(columns={'ra': 'RA', 'dec': 'DEC', 'z': 'zspec'})\n",
    "  df_search_copy.to_csv('outputs_v3/paulo/all_clusters.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_table('outputs_v3/clusters_v3.parque')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
